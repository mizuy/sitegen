= Statistics

:toc:

== 統計的検定

例として、これまでに得た知見などから、ある細胞Cへのある介入Iによりある遺伝子Gの発現が上昇するという仮説を立てたとする。

仮説が科学的に正しいためには、誰が何度やっても同じ実験では同じ結果がでなくてはいけない（再現性）。
誰が何度やっても、介入Iにより遺伝子Gの発現が明らかに上昇するようであれば、この仮説は明らかな科学的真実と主張できる。

すべての条件を同一にすることができる理想的な極限では、何度やっても遺伝子Gの発現の上昇は同じになるはずだ。
実際には、同じ条件で行った実験でも発現量にはばらつきができる。
このばらつきは隠れた条件の違いに起因する物と、測定誤差による見た目の値のぶれに分けられる。
隠れた条件の違いは、特に高レベルのレイヤーを扱う科学になればなるほど顕著になる。
(つまり、物理学より生物学が、生物学より社会学でばらつきは顕著になる。)

こうしたばらつきによって、仮説が正しいかどうか直感的に即答できないことがある。
統計的検定では、仮説が真実でないと仮定した時に、偶然測定データほどの変化が現れうる確率を数値的に定量化し、仮説が真実といえるかどうかを間接的に検証する方法である。

この例では、介入Iは発現量になんら変化を与えなく、見た目の変化はすべて隠れた条件の違いからくる偶然のばらつきによるものと仮定する。これを帰無仮説という。
帰無仮説の下、偶然のばらつきによって、測定データかもしくは測定データよりより顕著な発現量変化が現れうる確率を計算する。これをp-valueという。
p-valueがあらかじめ定めたある一定の低い確率(有意水準という)よりも低ければ、帰無仮説により測定データを説明できる根拠は低いとして、仮説が統計的に有意に正しいという結論を導く。

p-valueの計算法は、測定データの性質に応じて個々に計算をする必要がある。

== 大数の法則

同じ条件下でも複数回測定すると、その値はばらつくために真の値を直接観測することはできない。

今例として、介入I以前の遺伝子Gの発現量がxであるとわかっているとする。

同じ細胞を同じ条件で育て、片一方に介入Iを行い、片一方には行わず、その後遺伝子発現量を測定する、という実験をn回を行ったとする。
そのときの測定値を、介入Iを行った方が x1....xn, 行わなかった方が y1....ynとする。


== Student' t test (1-sample)

ある量Xをn回測定した結果 $X_n$ に基づいて、Xの期待値 $\mu = E(X)$ を推定したい

$$
\mu = lim_{n \rt \inf} \sum^n_i X_i
$$

n回測定した場合の平均値は、中心極限定理から正規分布に近いはず。XがN(\mu, \sigma^2) に従うとき、\sigmaが未知であっても

$$
t = \frac{\overline(X)-\mu}{\sqrt{s^2/n}}
$$

が、自由度 n-1 の t分布 に従う。

== 尺度

カテゴリー変数。名義尺度、順序尺度、

. 質的変数
.. 二値変数: 性別、生死
.. 名義変数: 病型、人種
.. 順序変数: 病気、スコア
. 量的変数
.. 比例性 比例変数 vs 間隔変数
.. 連続性 連続量 vs 離散量
.. 正規性 正規分布をとるかどうか
.. 等分散 分散が等しいかどうか

== 大数の法則
== 中心極限定理


== 仮説検定 (Neyman-Pearson)

. Step 1: 有意水準;significance level alphaを決める。
. Step 2: 帰無仮説;null hypothesisと対立仮説;alternative hypothesisをたてる。
. Step 3: 適切な検定統計量を選ぶ
.. 帰無仮説下での検定統計量の確率分布を知る
.. 検定統計量を計算する
. Step 4: p valueを計算する
. Step 5: 結論を述べる。
.. p value < alpha であれば、危険度αで帰無仮説を棄却し、対立仮説を採用する。

検定統計量:: 帰無仮説$H_0$が真である場合に理論的ふるまい（確率分布）が判明している変数。
Type 1 Error:: 帰無仮説$H_0$が真であるのに$H_0$を棄却してしまうこと。その確率はあらかじめ設定した有意水準(significance level α)と同じになる。
Type 2 Error:: 帰無仮説$H_0$が偽であるのに$H_0$を棄却できないこと。その確率をβと呼ぶ。
検出力(statistical power):: 1-β. 対立仮説が正しいと仮定して帰無仮説が棄却される確率。検出力を上げるには、標本数を増やす。

p-valueとは、帰無仮説$H_0$が真である場合に、実際に観察された検定統計量よりも極端な検定統計量が偶然観測される確率。（観測されたデータよりもっと帰無仮説から遠いデータが偶然観測される確率。）このp-valueが有意水準より低ければ、帰無仮説の元では起こりにくいことが起きたので、帰無仮説を棄却し、対立仮説を採用するといのがNeyman-Pearson流の仮説検定。

p-valueの値自体は結果の意味合いにあまり寄与しない。結果の意味をより正確に表現するため、効果量(effect size)と信頼区間(confidence intervals)を報告するほうがよいというのが時代の流れ。95%信頼区間をみれば、p<0.05かどうかが分かる。効果量とその誤差を中心に添えた考え方を「新しい統計学」と読んでいる。(http://thenewstatistics.com/itns)

- Step 1: 仮説を立てる。
    - 有意か有意でないかの二分法をやめ、効果の大きさを見積もる効果量を推定する仮説を立てる。
    - ◎「この治療でどれだけ効果(たとえば生存率の上昇)があるか？」×「この治療は効果があるか？」
- Step 2: 
    - 効果量とその95% 信頼区間を計算し、報告する。p値は無視する。
- Step 3:
    - メタアナリシスを行う。個々の研究で有意でなくても、あわせれば有意な結果がでることがある。

== 検定モデル

parametric testとnon-parametric test
:    parametric testでは、テストによって母集団の性質に何らかの仮定（正規分布であることや、等分散性）をおく。non-parametric testはそれらの仮定を緩くしても適応できる統計モデル。広く適応できるのがメリットで、デメリットとしては計算の面倒さと検定力が低くなる点がある。検定力は標本数がとても大きくなれば変わらなくなる。parametric testを第1選択、仮定が満たせなければnon-parametric testを使う。例えば標本数が少なく、正規性を仮定出来ない場合はparametric testは使えないのでnon-parametric testが重宝する。

. 母数（平均値・代表値）の比較
.. parametric test
... 平均値の検定
.... 1群の平均値を定数と比較 (1-sample t-test)(R: t.test)
.... 独立2群の比較（2-sample t-test）(R: t.test)
.... 対応のある2群の比較（Paried t-test）(R: t.test)
.... oneway ANOVA (R: oneway.test(var.equal=TRUE))
.... 等分散を仮定しないoneway ANOVA (Welch test) (R: oneway.test)
.... twoway ANOVA
.... 繰り返しのない twoway ANOVA
... 比率の検定 (z-test) (R: prop.test)
.... 1群の条件を満たすサンプルの割合（proportion）を定数と比較
.... 2群のproportion同士を比較
.. non-parametric test
... 代表値の検定
.... 独立2群の比較（Mann-Whitney's U test = Wilcox's rank sum test）(R: wilcox.test)
.... 独立3群以上の比較 (Kruskal-Wallis test) (R: kruskal.test)
.... 対応のある2群の代表値の比較（Wilcox's signed-rank test）(R: wilcox.test(pared=TRUE))
.... 対応のある3群以上の比較 (Friedman's test) (R: friedman.test)
. 独立性の判定
.. Chi-squared-test (R: chisq.test)
... データの適合度判定; test of goodness of fit
... 2つの因子が独立かどうかの判定; test of independence
.. Fisher's exact test (R: fisher.test)
... サンプル数が少ないときにChi-squaredの代わりに使える。
. 等分散の検定
.. 独立2標本　(R: var.test)
.. 独立k標本　バートレットの検定 (R: bartlett.test)
. 無相関検定
.. Pearson (R: cor.test)
.. Speaman (R: cor.test(method="spearman"))
.. Kendall (R: cor.test(method="kendall"))

.単変量解析における統計手法
|================
2.2+|            5+| 目的変数(転帰)
| 二値変数      | 名義変数      | 順位変数               | 数量(非正規)           | 数量(正規)
.5+|説明変数(要因) |二値変数     | 2x2 chi2 test | 2xn chi2 test | mann-Whitney/Wilcoxson | mann-Whitney/Wilcoxson | t test
|名義変数     | mx2 chi2 test | mxn chi2 test | Kruskal-Wallis         | Kruskal-Wallis         | 分散分析
|順序変数     | Cochran-Armitage/Mantel extension | - | 順位相関 | Jonckheere | Jonckheere
|数量(非正規) | - | - | - | 順位相関 | 順位相関
|数量(正規)   | - | - | - | 順位相関 | 相関、回帰
|================


== 多変量解析。回帰と分散分析

複数の要因がそれぞれ独立してどれほど転帰に関係しているかを解析する。

$$
f(outcome) = f(sex) + f(age) + f(pathology) + ....
$$

|==================
| model              | 目的変数         | 説明変数
| one-way ANOVA      | 1 量的変数       | 1 カテゴリー変数  
| two-way ANOVA      | 1 量的変数       | 2 カテゴリー変数  
| 単回帰             | 1 量的変数       | 1 量的変数        
| 重回帰             | 1 量的変数       | 2つ以上の量的変数 
| ロジスティック回帰 | 1 カテゴリー変数 | 1つ以上の量的変数 
| Cox 回帰           | 事象の発生する速度| 量的変数         
|==================

.多変量解析における統計手法
|================
|  | 2+| 説明変数(転帰)
|  |   | 二値変数      | 量的変数
.4+|説明変数(要因) |二値変数 | Logistic Regression/ Cox Regression | 重回帰 多元配置ANOVA, 共分散分析
|名義変数 2+| 要因ダミー変数化して二値変数手法を用いる
|順序変数 2+| 要因スコア化して二値変数手法を用いる
|数量     | Logistic Regression, Cox Regression | 重相関、重回帰
|================

多重共線性;multiple co-linearity:: 強い相関のある2つの変数を多変量解析の説明変数に入れると、解析結果が大きく変動する。あらかじめ説明変数間の相関をみて、強い多重共線性がある場合は一方を除外するか、両変数を一括化して一つの説明変数にする。

.多重線形回帰(重回帰)
\[$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n
$$\]

.Logistic regression
\[$$
logit(x) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n
$$\]

\[$$
logit(x) = \ln \frac{p(x)}{1-p(x)}
$$\]

.Cox regression
\[$$
\ln\lambda(t) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n
$$\]

\[$$
\lambda(t) = \frac{\frac{d S(t)}{dt}}{S(t)}
$$\]

== Survival analysis

生存関数、ハザード関数、累積ハザード関数

生存関数 $S(t)$:: 個体がt時間を超えて生きている確率。
ハザード関数 $h(t)$ :: 個体がt時間まで生きていた前提で、その時点で死ぬ瞬間死亡率。
累積ハザード関数 $H(t)$ :: $H(t) = \int h(t)$ 

死亡までの時間を確率変数T、その密度関数をf(t)とする。

[latexmath]
+++++++++++
\begin{aligned}
S(t) & = Prob(T \leq t) = \int^{\infty}_{t} f(t) dt \\
h(h) & = \lim_{\Delta t \rightarrow 0} \frac{Prob(t \leq T \lt t + \Delta t \mid T \geq t)}{\Delta t} \\
     & = \lim_{\Delta t \rightarrow 0} \frac{S(t) - S(t+\Delta t)}{\Delta t \cdot S(t)} \\
     & = - \frac{dS(t)}{dt} \cdot \frac{1}{S(t)} \\
     & = - \frac{d (\log S(t))}{dt} \\
H(t) & = \int^{t}_{0} hu(u) dt = - \log S(t) \\
\end{aligned}
+++++++++++

Sとhは次のような関係で結ばれている。

[latexmath]
++++
\[
S(t) = \exp (- \int^{t}_{0} hu(u) dt ) \\
h(t) = - \frac{d (\log S(t))}{dt}
\]
++++

例として、放射線などによるone-hit modelは

\[
\frac{dS(t)}{dt} = - \lambda S(t)
\]

これをとくと

\[
S(t) = \exp(- \lambda t) \\
h(t) = \lambda
\]

ハザード関数が定数になる最も簡単なモデル。

Log rank test:: 全経過を転帰の発生を必ず含む多数の期間に分割し、それぞれの期間について2x2の分割表を作成してchi^2 testを行い、前期間分を統合して統計量を算出する方法。
